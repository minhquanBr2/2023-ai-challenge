{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5fcc581b",
   "metadata": {},
   "source": [
    "# Hướng dẫn truy vấn dữ liệu thị giác dùng fiftyone\n",
    "\n",
    "Đây là hướng dẫn dùng cho các đội tham dự AI Challenge 2023. Hướng dẫn này nhằm mục đích giới thiệu cho các đội một phương pháp cơ bản để truy vấn dữ liệu dựa trên thông tin BTC cung cấp và giới thiệu công cụ fiftyone để hỗ trợ đội thi đánh giá kết quả.\n",
    "\n",
    "## Cài đặt ban đầu\n",
    "\n",
    "Bạn cần cài đặt môi trường để chạy được notebook này trên máy tính cá nhân của bạn. Hướng dẫn này không bao gồm phần cài đặt môi trường. Khuyến nghị: các bạn có thể cài đặt [Anaconda](https://docs.anaconda.com/free/anaconda/install/windows/).\n",
    "\n",
    "## Cài đặt các thư viện FiftyOne và PyTorch\n",
    "Hướng dẫn này dùng fiftyone là công cụ để trực quan dữ liệu và pytorch là backend chính cho các thuật toán máy học.\n",
    "\n",
    "### Lưu ý: Đối với các bạn dùng Windows nên dùng bản fiftyone **v0.21.4**, không nên dùng bản mới nhất!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f5a576d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: fiftyone==0.21.4 in c:\\users\\pc\\aic2023\\lib\\site-packages (0.21.4)\n",
      "Requirement already satisfied: aiofiles in c:\\users\\pc\\aic2023\\lib\\site-packages (from fiftyone==0.21.4) (23.2.1)\n",
      "Requirement already satisfied: argcomplete in c:\\users\\pc\\aic2023\\lib\\site-packages (from fiftyone==0.21.4) (3.1.1)\n",
      "Requirement already satisfied: boto3 in c:\\users\\pc\\aic2023\\lib\\site-packages (from fiftyone==0.21.4) (1.28.30)\n",
      "Requirement already satisfied: cachetools in c:\\users\\pc\\aic2023\\lib\\site-packages (from fiftyone==0.21.4) (5.3.1)\n",
      "Requirement already satisfied: dacite<1.8.0,>=1.6.0 in c:\\users\\pc\\aic2023\\lib\\site-packages (from fiftyone==0.21.4) (1.7.0)\n",
      "Requirement already satisfied: Deprecated in c:\\users\\pc\\aic2023\\lib\\site-packages (from fiftyone==0.21.4) (1.2.14)\n",
      "Requirement already satisfied: eventlet in c:\\users\\pc\\aic2023\\lib\\site-packages (from fiftyone==0.21.4) (0.33.3)\n",
      "Requirement already satisfied: ftfy in c:\\users\\pc\\aic2023\\lib\\site-packages (from fiftyone==0.21.4) (6.1.1)\n",
      "Requirement already satisfied: future in c:\\users\\pc\\aic2023\\lib\\site-packages (from fiftyone==0.21.4) (0.18.3)\n",
      "Requirement already satisfied: hypercorn>=0.13.2 in c:\\users\\pc\\aic2023\\lib\\site-packages (from fiftyone==0.21.4) (0.14.4)\n",
      "Requirement already satisfied: Jinja2>=3 in c:\\users\\pc\\aic2023\\lib\\site-packages (from fiftyone==0.21.4) (3.1.2)\n",
      "Requirement already satisfied: kaleido in c:\\users\\pc\\aic2023\\lib\\site-packages (from fiftyone==0.21.4) (0.2.1)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\pc\\aic2023\\lib\\site-packages (from fiftyone==0.21.4) (3.7.2)\n",
      "Requirement already satisfied: mongoengine==0.24.2 in c:\\users\\pc\\aic2023\\lib\\site-packages (from fiftyone==0.21.4) (0.24.2)\n",
      "Requirement already satisfied: motor>=2.5 in c:\\users\\pc\\aic2023\\lib\\site-packages (from fiftyone==0.21.4) (3.2.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\pc\\aic2023\\lib\\site-packages (from fiftyone==0.21.4) (1.24.4)\n",
      "Requirement already satisfied: packaging in c:\\users\\pc\\aic2023\\lib\\site-packages (from fiftyone==0.21.4) (23.1)\n",
      "Requirement already satisfied: pandas in c:\\users\\pc\\aic2023\\lib\\site-packages (from fiftyone==0.21.4) (2.0.3)\n",
      "Requirement already satisfied: Pillow>=6.2 in c:\\users\\pc\\aic2023\\lib\\site-packages (from fiftyone==0.21.4) (10.0.0)\n",
      "Requirement already satisfied: plotly>=4.14 in c:\\users\\pc\\aic2023\\lib\\site-packages (from fiftyone==0.21.4) (5.16.1)\n",
      "Requirement already satisfied: pprintpp in c:\\users\\pc\\aic2023\\lib\\site-packages (from fiftyone==0.21.4) (0.4.0)\n",
      "Requirement already satisfied: psutil in c:\\users\\pc\\aic2023\\lib\\site-packages (from fiftyone==0.21.4) (5.9.5)\n",
      "Requirement already satisfied: pymongo>=3.12 in c:\\users\\pc\\aic2023\\lib\\site-packages (from fiftyone==0.21.4) (4.4.1)\n",
      "Requirement already satisfied: pytz in c:\\users\\pc\\aic2023\\lib\\site-packages (from fiftyone==0.21.4) (2023.3)\n",
      "Requirement already satisfied: PyYAML in c:\\users\\pc\\aic2023\\lib\\site-packages (from fiftyone==0.21.4) (6.0.1)\n",
      "Requirement already satisfied: regex in c:\\users\\pc\\aic2023\\lib\\site-packages (from fiftyone==0.21.4) (2023.8.8)\n",
      "Requirement already satisfied: retrying in c:\\users\\pc\\aic2023\\lib\\site-packages (from fiftyone==0.21.4) (1.3.4)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\pc\\aic2023\\lib\\site-packages (from fiftyone==0.21.4) (1.3.0)\n",
      "Requirement already satisfied: scikit-image in c:\\users\\pc\\aic2023\\lib\\site-packages (from fiftyone==0.21.4) (0.21.0)\n",
      "Requirement already satisfied: setuptools in c:\\users\\pc\\aic2023\\lib\\site-packages (from fiftyone==0.21.4) (65.5.0)\n",
      "Requirement already satisfied: sseclient-py<2,>=1.7.2 in c:\\users\\pc\\aic2023\\lib\\site-packages (from fiftyone==0.21.4) (1.7.2)\n",
      "Requirement already satisfied: sse-starlette<1,>=0.10.3 in c:\\users\\pc\\aic2023\\lib\\site-packages (from fiftyone==0.21.4) (0.10.3)\n",
      "Requirement already satisfied: starlette<0.27,>=0.24.0 in c:\\users\\pc\\aic2023\\lib\\site-packages (from fiftyone==0.21.4) (0.26.1)\n",
      "Requirement already satisfied: strawberry-graphql==0.138.1 in c:\\users\\pc\\aic2023\\lib\\site-packages (from fiftyone==0.21.4) (0.138.1)\n",
      "Requirement already satisfied: tabulate in c:\\users\\pc\\aic2023\\lib\\site-packages (from fiftyone==0.21.4) (0.9.0)\n",
      "Requirement already satisfied: xmltodict in c:\\users\\pc\\aic2023\\lib\\site-packages (from fiftyone==0.21.4) (0.13.0)\n",
      "Requirement already satisfied: universal-analytics-python3<2,>=1.0.1 in c:\\users\\pc\\aic2023\\lib\\site-packages (from fiftyone==0.21.4) (1.1.1)\n",
      "Requirement already satisfied: fiftyone-brain<0.14,>=0.13 in c:\\users\\pc\\aic2023\\lib\\site-packages (from fiftyone==0.21.4) (0.13.1)\n",
      "Requirement already satisfied: fiftyone-db<0.5,>=0.4 in c:\\users\\pc\\aic2023\\lib\\site-packages (from fiftyone==0.21.4) (0.4.0)\n",
      "Requirement already satisfied: voxel51-eta<0.11,>=0.10 in c:\\users\\pc\\aic2023\\lib\\site-packages (from fiftyone==0.21.4) (0.10.0)\n",
      "Requirement already satisfied: opencv-python-headless in c:\\users\\pc\\aic2023\\lib\\site-packages (from fiftyone==0.21.4) (4.8.0.76)\n",
      "Requirement already satisfied: graphql-core<3.3.0,>=3.2.0 in c:\\users\\pc\\aic2023\\lib\\site-packages (from strawberry-graphql==0.138.1->fiftyone==0.21.4) (3.2.3)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.7.0 in c:\\users\\pc\\aic2023\\lib\\site-packages (from strawberry-graphql==0.138.1->fiftyone==0.21.4) (2.8.2)\n",
      "Requirement already satisfied: typing_extensions<5.0.0,>=3.7.4 in c:\\users\\pc\\aic2023\\lib\\site-packages (from strawberry-graphql==0.138.1->fiftyone==0.21.4) (4.7.1)\n",
      "Requirement already satisfied: scipy>=1.2.0 in c:\\users\\pc\\aic2023\\lib\\site-packages (from fiftyone-brain<0.14,>=0.13->fiftyone==0.21.4) (1.11.2)\n",
      "Requirement already satisfied: h11 in c:\\users\\pc\\aic2023\\lib\\site-packages (from hypercorn>=0.13.2->fiftyone==0.21.4) (0.14.0)\n",
      "Requirement already satisfied: h2>=3.1.0 in c:\\users\\pc\\aic2023\\lib\\site-packages (from hypercorn>=0.13.2->fiftyone==0.21.4) (4.1.0)\n",
      "Requirement already satisfied: priority in c:\\users\\pc\\aic2023\\lib\\site-packages (from hypercorn>=0.13.2->fiftyone==0.21.4) (2.0.0)\n",
      "Requirement already satisfied: wsproto>=0.14.0 in c:\\users\\pc\\aic2023\\lib\\site-packages (from hypercorn>=0.13.2->fiftyone==0.21.4) (1.2.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\pc\\aic2023\\lib\\site-packages (from Jinja2>=3->fiftyone==0.21.4) (2.1.3)\n",
      "Requirement already satisfied: tenacity>=6.2.0 in c:\\users\\pc\\aic2023\\lib\\site-packages (from plotly>=4.14->fiftyone==0.21.4) (8.2.3)\n",
      "Requirement already satisfied: dnspython<3.0.0,>=1.16.0 in c:\\users\\pc\\aic2023\\lib\\site-packages (from pymongo>=3.12->fiftyone==0.21.4) (2.4.2)\n",
      "Requirement already satisfied: anyio<5,>=3.4.0 in c:\\users\\pc\\aic2023\\lib\\site-packages (from starlette<0.27,>=0.24.0->fiftyone==0.21.4) (3.7.1)\n",
      "Requirement already satisfied: httpx>=0.10.0 in c:\\users\\pc\\aic2023\\lib\\site-packages (from universal-analytics-python3<2,>=1.0.1->fiftyone==0.21.4) (0.24.1)\n",
      "Requirement already satisfied: dill in c:\\users\\pc\\aic2023\\lib\\site-packages (from voxel51-eta<0.11,>=0.10->fiftyone==0.21.4) (0.3.7)\n",
      "Requirement already satisfied: glob2 in c:\\users\\pc\\aic2023\\lib\\site-packages (from voxel51-eta<0.11,>=0.10->fiftyone==0.21.4) (0.7)\n",
      "Requirement already satisfied: jsonlines in c:\\users\\pc\\aic2023\\lib\\site-packages (from voxel51-eta<0.11,>=0.10->fiftyone==0.21.4) (3.1.0)\n",
      "Requirement already satisfied: py7zr in c:\\users\\pc\\aic2023\\lib\\site-packages (from voxel51-eta<0.11,>=0.10->fiftyone==0.21.4) (0.20.6)\n",
      "Requirement already satisfied: rarfile in c:\\users\\pc\\aic2023\\lib\\site-packages (from voxel51-eta<0.11,>=0.10->fiftyone==0.21.4) (4.0)\n",
      "Requirement already satisfied: requests in c:\\users\\pc\\aic2023\\lib\\site-packages (from voxel51-eta<0.11,>=0.10->fiftyone==0.21.4) (2.31.0)\n",
      "Requirement already satisfied: six in c:\\users\\pc\\aic2023\\lib\\site-packages (from voxel51-eta<0.11,>=0.10->fiftyone==0.21.4) (1.16.0)\n",
      "Requirement already satisfied: sortedcontainers in c:\\users\\pc\\aic2023\\lib\\site-packages (from voxel51-eta<0.11,>=0.10->fiftyone==0.21.4) (2.4.0)\n",
      "Requirement already satisfied: tzlocal in c:\\users\\pc\\aic2023\\lib\\site-packages (from voxel51-eta<0.11,>=0.10->fiftyone==0.21.4) (5.0.1)\n",
      "Requirement already satisfied: urllib3 in c:\\users\\pc\\aic2023\\lib\\site-packages (from voxel51-eta<0.11,>=0.10->fiftyone==0.21.4) (1.26.16)\n",
      "Requirement already satisfied: botocore<1.32.0,>=1.31.30 in c:\\users\\pc\\aic2023\\lib\\site-packages (from boto3->fiftyone==0.21.4) (1.31.30)\n",
      "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in c:\\users\\pc\\aic2023\\lib\\site-packages (from boto3->fiftyone==0.21.4) (1.0.1)\n",
      "Requirement already satisfied: s3transfer<0.7.0,>=0.6.0 in c:\\users\\pc\\aic2023\\lib\\site-packages (from boto3->fiftyone==0.21.4) (0.6.2)\n",
      "Requirement already satisfied: wrapt<2,>=1.10 in c:\\users\\pc\\aic2023\\lib\\site-packages (from Deprecated->fiftyone==0.21.4) (1.15.0)\n",
      "Requirement already satisfied: greenlet>=0.3 in c:\\users\\pc\\aic2023\\lib\\site-packages (from eventlet->fiftyone==0.21.4) (2.0.2)\n",
      "Requirement already satisfied: wcwidth>=0.2.5 in c:\\users\\pc\\aic2023\\lib\\site-packages (from ftfy->fiftyone==0.21.4) (0.2.6)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\pc\\aic2023\\lib\\site-packages (from matplotlib->fiftyone==0.21.4) (1.1.0)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\pc\\aic2023\\lib\\site-packages (from matplotlib->fiftyone==0.21.4) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\pc\\aic2023\\lib\\site-packages (from matplotlib->fiftyone==0.21.4) (4.42.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\pc\\aic2023\\lib\\site-packages (from matplotlib->fiftyone==0.21.4) (1.4.4)\n",
      "Requirement already satisfied: pyparsing<3.1,>=2.3.1 in c:\\users\\pc\\aic2023\\lib\\site-packages (from matplotlib->fiftyone==0.21.4) (3.0.9)\n",
      "Requirement already satisfied: tzdata>=2022.1 in c:\\users\\pc\\aic2023\\lib\\site-packages (from pandas->fiftyone==0.21.4) (2023.3)\n",
      "Requirement already satisfied: networkx>=2.8 in c:\\users\\pc\\aic2023\\lib\\site-packages (from scikit-image->fiftyone==0.21.4) (3.1)\n",
      "Requirement already satisfied: imageio>=2.27 in c:\\users\\pc\\aic2023\\lib\\site-packages (from scikit-image->fiftyone==0.21.4) (2.31.1)\n",
      "Requirement already satisfied: tifffile>=2022.8.12 in c:\\users\\pc\\aic2023\\lib\\site-packages (from scikit-image->fiftyone==0.21.4) (2023.8.12)\n",
      "Requirement already satisfied: PyWavelets>=1.1.1 in c:\\users\\pc\\aic2023\\lib\\site-packages (from scikit-image->fiftyone==0.21.4) (1.4.1)\n",
      "Requirement already satisfied: lazy_loader>=0.2 in c:\\users\\pc\\aic2023\\lib\\site-packages (from scikit-image->fiftyone==0.21.4) (0.3)\n",
      "Requirement already satisfied: joblib>=1.1.1 in c:\\users\\pc\\aic2023\\lib\\site-packages (from scikit-learn->fiftyone==0.21.4) (1.3.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\pc\\aic2023\\lib\\site-packages (from scikit-learn->fiftyone==0.21.4) (3.2.0)\n",
      "Requirement already satisfied: idna>=2.8 in c:\\users\\pc\\aic2023\\lib\\site-packages (from anyio<5,>=3.4.0->starlette<0.27,>=0.24.0->fiftyone==0.21.4) (3.4)\n",
      "Requirement already satisfied: sniffio>=1.1 in c:\\users\\pc\\aic2023\\lib\\site-packages (from anyio<5,>=3.4.0->starlette<0.27,>=0.24.0->fiftyone==0.21.4) (1.3.0)\n",
      "Requirement already satisfied: hyperframe<7,>=6.0 in c:\\users\\pc\\aic2023\\lib\\site-packages (from h2>=3.1.0->hypercorn>=0.13.2->fiftyone==0.21.4) (6.0.1)\n",
      "Requirement already satisfied: hpack<5,>=4.0 in c:\\users\\pc\\aic2023\\lib\\site-packages (from h2>=3.1.0->hypercorn>=0.13.2->fiftyone==0.21.4) (4.0.0)\n",
      "Requirement already satisfied: certifi in c:\\users\\pc\\aic2023\\lib\\site-packages (from httpx>=0.10.0->universal-analytics-python3<2,>=1.0.1->fiftyone==0.21.4) (2023.7.22)\n",
      "Requirement already satisfied: httpcore<0.18.0,>=0.15.0 in c:\\users\\pc\\aic2023\\lib\\site-packages (from httpx>=0.10.0->universal-analytics-python3<2,>=1.0.1->fiftyone==0.21.4) (0.17.3)\n",
      "Requirement already satisfied: attrs>=19.2.0 in c:\\users\\pc\\aic2023\\lib\\site-packages (from jsonlines->voxel51-eta<0.11,>=0.10->fiftyone==0.21.4) (23.1.0)\n",
      "Requirement already satisfied: texttable in c:\\users\\pc\\aic2023\\lib\\site-packages (from py7zr->voxel51-eta<0.11,>=0.10->fiftyone==0.21.4) (1.6.7)\n",
      "Requirement already satisfied: pycryptodomex>=3.6.6 in c:\\users\\pc\\aic2023\\lib\\site-packages (from py7zr->voxel51-eta<0.11,>=0.10->fiftyone==0.21.4) (3.18.0)\n",
      "Requirement already satisfied: pyzstd>=0.14.4 in c:\\users\\pc\\aic2023\\lib\\site-packages (from py7zr->voxel51-eta<0.11,>=0.10->fiftyone==0.21.4) (0.15.9)\n",
      "Requirement already satisfied: pyppmd<1.1.0,>=0.18.1 in c:\\users\\pc\\aic2023\\lib\\site-packages (from py7zr->voxel51-eta<0.11,>=0.10->fiftyone==0.21.4) (1.0.0)\n",
      "Requirement already satisfied: pybcj>=0.6.0 in c:\\users\\pc\\aic2023\\lib\\site-packages (from py7zr->voxel51-eta<0.11,>=0.10->fiftyone==0.21.4) (1.0.1)\n",
      "Requirement already satisfied: multivolumefile>=0.2.3 in c:\\users\\pc\\aic2023\\lib\\site-packages (from py7zr->voxel51-eta<0.11,>=0.10->fiftyone==0.21.4) (0.2.3)\n",
      "Requirement already satisfied: brotli>=1.0.9 in c:\\users\\pc\\aic2023\\lib\\site-packages (from py7zr->voxel51-eta<0.11,>=0.10->fiftyone==0.21.4) (1.0.9)\n",
      "Requirement already satisfied: inflate64>=0.3.1 in c:\\users\\pc\\aic2023\\lib\\site-packages (from py7zr->voxel51-eta<0.11,>=0.10->fiftyone==0.21.4) (0.3.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\pc\\aic2023\\lib\\site-packages (from requests->voxel51-eta<0.11,>=0.10->fiftyone==0.21.4) (3.2.0)\n",
      "Requirement already satisfied: torch in c:\\users\\pc\\aic2023\\lib\\site-packages (2.0.1)\n",
      "Requirement already satisfied: torchvision in c:\\users\\pc\\aic2023\\lib\\site-packages (0.15.2)\n",
      "Requirement already satisfied: torchaudio in c:\\users\\pc\\aic2023\\lib\\site-packages (2.0.2)\n",
      "Requirement already satisfied: filelock in c:\\users\\pc\\aic2023\\lib\\site-packages (from torch) (3.12.2)\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\pc\\aic2023\\lib\\site-packages (from torch) (4.7.1)\n",
      "Requirement already satisfied: sympy in c:\\users\\pc\\aic2023\\lib\\site-packages (from torch) (1.12)\n",
      "Requirement already satisfied: networkx in c:\\users\\pc\\aic2023\\lib\\site-packages (from torch) (3.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\pc\\aic2023\\lib\\site-packages (from torch) (3.1.2)\n",
      "Requirement already satisfied: numpy in c:\\users\\pc\\aic2023\\lib\\site-packages (from torchvision) (1.24.4)\n",
      "Requirement already satisfied: requests in c:\\users\\pc\\aic2023\\lib\\site-packages (from torchvision) (2.31.0)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in c:\\users\\pc\\aic2023\\lib\\site-packages (from torchvision) (10.0.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\pc\\aic2023\\lib\\site-packages (from jinja2->torch) (2.1.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\pc\\aic2023\\lib\\site-packages (from requests->torchvision) (3.2.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\pc\\aic2023\\lib\\site-packages (from requests->torchvision) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\pc\\aic2023\\lib\\site-packages (from requests->torchvision) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\pc\\aic2023\\lib\\site-packages (from requests->torchvision) (2023.7.22)\n",
      "Requirement already satisfied: mpmath>=0.19 in c:\\users\\pc\\aic2023\\lib\\site-packages (from sympy->torch) (1.3.0)\n"
     ]
    }
   ],
   "source": [
    "! pip install fiftyone==0.21.4\n",
    "! pip install torch torchvision torchaudio\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb9afb40",
   "metadata": {},
   "source": [
    "Load dữ liệu keyframe từ thư mục chứa keyframe. Mỗi ảnh và thông tin đi kèm sau này sẽ được lưu trữ trong một Sample. Tất cả các Sample được lưu trong Dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "357d4489",
   "metadata": {},
   "outputs": [],
   "source": [
    "import fiftyone as fo\n",
    "import fiftyone.brain as fob\n",
    "import fiftyone.zoo as foz\n",
    "import numpy as np\n",
    "from glob import glob\n",
    "import json\n",
    "import os\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36b7ba43",
   "metadata": {},
   "source": [
    "Load dữ liệu keyframe từ thư mục chứa keyframe. Trong hướng dẫn này tất cả các file Keyframes_L*.zip được giải nén vào thư mục `D:\\AIC\\Keyframes`. Mỗi ảnh và thông tin đi kèm sau này sẽ được lưu trữ trong một `Sample`. Tất cả các `Sample` được lưu trong `Dataset`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9e072688",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset = fo.Dataset.from_images_dir('D:\\\\CS\\\\2023 HCM AI CHALLENGE\\\\keyframes', name=None, tags=None, recursive=True)\n",
    "dataset = fo.load_dataset('aic2023-kf-1')\n",
    "# dataset.persistent = True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b89e71c",
   "metadata": {},
   "source": [
    "Sau khi dữ liệu đã load lên xong. Bạn có thể truy cập vào đường vào ứng dụng web của fiftyone từ [http://localhost:5151](http://localhost:5151)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "58be11b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Could not connect session, trying again in 10 seconds\n",
      "\n",
      "Session launched. Run `session.show()` to open the App in a cell output.\n"
     ]
    }
   ],
   "source": [
    "session = fo.launch_app(dataset, auto=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "078ce744",
   "metadata": {},
   "source": [
    "Hoặc bạn có thể chạy cell bên dưới để mở tab mới cho ứng dụng web fiftyone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bce0d9ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# session.open_tab()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28298924",
   "metadata": {},
   "source": [
    "### Trích xuất thêm thông tin tên của video và frameid\n",
    "Thông tin `video` và `frameid` sẽ được lấy từ tên của tập tin keyframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a8ee02ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for sample in dataset:\n",
    "#     _, sample['video'], sample['frameid'] = sample['filepath'][:-4].rsplit('\\\\', 2)\n",
    "#     sample.save()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11d66008",
   "metadata": {},
   "source": [
    "Bạn có thể xem `Sample` đầu tiên của `Dataset` bằng lệnh sau:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6997ef1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(dataset.first())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4309a34f",
   "metadata": {},
   "source": [
    "### Thêm thông tin kết quả của object detection.\n",
    "\n",
    "Bước này có thể tốn của bạn nhiều thời gian để đọc hết tất cả các dữ liệu về object detection. Bạn có thể bỏ qua cell này và chạy cell này sau nếu muốn thử thêm các thông tin về vector CLIP embedding trước."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad1c4395",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for sample in dataset:\n",
    "#     object_path = f\"D:\\\\CS\\\\2023 HCM AI CHALLENGE\\\\objects\\\\{sample['video']}\\\\{sample['frameid']}.json\"\n",
    "#     with open(object_path) as jsonfile:\n",
    "#         det_data = json.load(jsonfile)\n",
    "#     detections = []\n",
    "#     for cls, box, score in zip(det_data['detection_class_entities'], det_data['detection_boxes'], det_data['detection_scores']):\n",
    "#         # Convert to [top-left-x, top-left-y, width, height]\n",
    "#         boxf = [float(box[1]), float(box[0]), float(box[3]) - float(box[1]), float(box[2]) - float(box[0])]\n",
    "#         scoref = float(score)\n",
    "        \n",
    "#         # Only add objects with confidence > 0.4\n",
    "#         if scoref > 0.4:\n",
    "#             detections.append(\n",
    "#                 fo.Detection(\n",
    "#                     label=cls,\n",
    "#                     bounding_box= boxf,\n",
    "#                     confidence=float(score)\n",
    "#                 )\n",
    "#             )\n",
    "#     sample[\"object_faster_rcnn\"] = fo.Detections(detections=detections)\n",
    "#     sample.save()\n",
    "                           "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e287dbb4",
   "metadata": {},
   "source": [
    "### Thêm thông tin CLIP embedding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "58d5d9ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_keyframe = glob('D:\\\\CS\\\\2023 HCM AI CHALLENGE\\\\keyframes\\\\*\\\\*.jpg')\n",
    "video_keyframe_dict = {}\n",
    "all_video = glob('D:\\\\CS\\\\2023 HCM AI CHALLENGE\\\\keyframes\\\\*')  \n",
    "all_video = [v.rsplit('\\\\',1)[-1] for v in all_video]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53460b70",
   "metadata": {},
   "source": [
    "Đọc thông tin clip embedding được cung cấp.\n",
    "\n",
    "Lưu ý: Các bạn cần tải đúng bản CLIP embedding từ model **CLIP ViT-B/32**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb927629",
   "metadata": {},
   "source": [
    "Tạo dictionary `video_keyframe_dict` với `video_keyframe_dict[video]` thông tin danh sách `keyframe` của `video` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f33da133",
   "metadata": {},
   "outputs": [],
   "source": [
    "for kf in all_keyframe:\n",
    "    _, vid, kf = kf[:-4].rsplit('\\\\',2)\n",
    "    if vid not in video_keyframe_dict.keys():\n",
    "        video_keyframe_dict[vid] = [kf]\n",
    "    else:\n",
    "        video_keyframe_dict[vid].append(kf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faefe0bf",
   "metadata": {},
   "source": [
    "Do thông tin vector CLIP embedding được cung cấp được lưu theo từng video nhầm mục đích tối ưu thời gian đọc dữ liệu. Cần sort lại danh sách `keyframe` của từng `video` để đảm bảo thứ tự đọc đúng với vector embedding được cung cấp."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4b0fad7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "for k,v in video_keyframe_dict.items():\n",
    "    video_keyframe_dict[k] = sorted(v)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d99d121",
   "metadata": {},
   "source": [
    "Tạo dictionary `embedding_dict` với `embedding_dict[video][keyframe]` lưu thông tin vector CLIP embedding của `keyframe` trong `video` tương ứng"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a5d94d7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:\\CS\\2023 HCM AI CHALLENGE\\clip-features-vit-b32\\L01_V001.npy\n",
      "D:\\CS\\2023 HCM AI CHALLENGE\\clip-features-vit-b32\\L01_V002.npy\n",
      "D:\\CS\\2023 HCM AI CHALLENGE\\clip-features-vit-b32\\L01_V003.npy\n",
      "D:\\CS\\2023 HCM AI CHALLENGE\\clip-features-vit-b32\\L01_V004.npy\n",
      "D:\\CS\\2023 HCM AI CHALLENGE\\clip-features-vit-b32\\L01_V005.npy\n",
      "D:\\CS\\2023 HCM AI CHALLENGE\\clip-features-vit-b32\\L01_V006.npy\n",
      "D:\\CS\\2023 HCM AI CHALLENGE\\clip-features-vit-b32\\L01_V007.npy\n",
      "D:\\CS\\2023 HCM AI CHALLENGE\\clip-features-vit-b32\\L01_V008.npy\n",
      "D:\\CS\\2023 HCM AI CHALLENGE\\clip-features-vit-b32\\L01_V009.npy\n",
      "D:\\CS\\2023 HCM AI CHALLENGE\\clip-features-vit-b32\\L01_V010.npy\n",
      "D:\\CS\\2023 HCM AI CHALLENGE\\clip-features-vit-b32\\L01_V011.npy\n",
      "D:\\CS\\2023 HCM AI CHALLENGE\\clip-features-vit-b32\\L01_V012.npy\n",
      "D:\\CS\\2023 HCM AI CHALLENGE\\clip-features-vit-b32\\L01_V013.npy\n",
      "D:\\CS\\2023 HCM AI CHALLENGE\\clip-features-vit-b32\\L01_V014.npy\n",
      "D:\\CS\\2023 HCM AI CHALLENGE\\clip-features-vit-b32\\L01_V015.npy\n",
      "D:\\CS\\2023 HCM AI CHALLENGE\\clip-features-vit-b32\\L01_V016.npy\n",
      "D:\\CS\\2023 HCM AI CHALLENGE\\clip-features-vit-b32\\L01_V017.npy\n",
      "D:\\CS\\2023 HCM AI CHALLENGE\\clip-features-vit-b32\\L01_V018.npy\n",
      "D:\\CS\\2023 HCM AI CHALLENGE\\clip-features-vit-b32\\L01_V019.npy\n",
      "D:\\CS\\2023 HCM AI CHALLENGE\\clip-features-vit-b32\\L01_V020.npy\n",
      "D:\\CS\\2023 HCM AI CHALLENGE\\clip-features-vit-b32\\L01_V021.npy\n",
      "D:\\CS\\2023 HCM AI CHALLENGE\\clip-features-vit-b32\\L01_V022.npy\n",
      "D:\\CS\\2023 HCM AI CHALLENGE\\clip-features-vit-b32\\L01_V023.npy\n",
      "D:\\CS\\2023 HCM AI CHALLENGE\\clip-features-vit-b32\\L01_V024.npy\n",
      "D:\\CS\\2023 HCM AI CHALLENGE\\clip-features-vit-b32\\L01_V025.npy\n",
      "D:\\CS\\2023 HCM AI CHALLENGE\\clip-features-vit-b32\\L01_V026.npy\n",
      "D:\\CS\\2023 HCM AI CHALLENGE\\clip-features-vit-b32\\L01_V027.npy\n",
      "D:\\CS\\2023 HCM AI CHALLENGE\\clip-features-vit-b32\\L01_V028.npy\n",
      "D:\\CS\\2023 HCM AI CHALLENGE\\clip-features-vit-b32\\L01_V029.npy\n",
      "D:\\CS\\2023 HCM AI CHALLENGE\\clip-features-vit-b32\\L01_V030.npy\n",
      "D:\\CS\\2023 HCM AI CHALLENGE\\clip-features-vit-b32\\L01_V031.npy\n",
      "D:\\CS\\2023 HCM AI CHALLENGE\\clip-features-vit-b32\\L02_V001.npy\n",
      "D:\\CS\\2023 HCM AI CHALLENGE\\clip-features-vit-b32\\L02_V002.npy\n",
      "D:\\CS\\2023 HCM AI CHALLENGE\\clip-features-vit-b32\\L02_V003.npy\n",
      "D:\\CS\\2023 HCM AI CHALLENGE\\clip-features-vit-b32\\L02_V004.npy\n",
      "D:\\CS\\2023 HCM AI CHALLENGE\\clip-features-vit-b32\\L02_V005.npy\n",
      "D:\\CS\\2023 HCM AI CHALLENGE\\clip-features-vit-b32\\L02_V006.npy\n",
      "D:\\CS\\2023 HCM AI CHALLENGE\\clip-features-vit-b32\\L02_V007.npy\n",
      "D:\\CS\\2023 HCM AI CHALLENGE\\clip-features-vit-b32\\L02_V008.npy\n",
      "D:\\CS\\2023 HCM AI CHALLENGE\\clip-features-vit-b32\\L02_V009.npy\n",
      "D:\\CS\\2023 HCM AI CHALLENGE\\clip-features-vit-b32\\L02_V010.npy\n",
      "D:\\CS\\2023 HCM AI CHALLENGE\\clip-features-vit-b32\\L02_V011.npy\n",
      "D:\\CS\\2023 HCM AI CHALLENGE\\clip-features-vit-b32\\L02_V012.npy\n",
      "D:\\CS\\2023 HCM AI CHALLENGE\\clip-features-vit-b32\\L02_V013.npy\n",
      "D:\\CS\\2023 HCM AI CHALLENGE\\clip-features-vit-b32\\L02_V014.npy\n",
      "D:\\CS\\2023 HCM AI CHALLENGE\\clip-features-vit-b32\\L02_V015.npy\n",
      "D:\\CS\\2023 HCM AI CHALLENGE\\clip-features-vit-b32\\L02_V016.npy\n",
      "D:\\CS\\2023 HCM AI CHALLENGE\\clip-features-vit-b32\\L02_V017.npy\n",
      "D:\\CS\\2023 HCM AI CHALLENGE\\clip-features-vit-b32\\L02_V018.npy\n",
      "D:\\CS\\2023 HCM AI CHALLENGE\\clip-features-vit-b32\\L02_V019.npy\n",
      "D:\\CS\\2023 HCM AI CHALLENGE\\clip-features-vit-b32\\L02_V020.npy\n",
      "D:\\CS\\2023 HCM AI CHALLENGE\\clip-features-vit-b32\\L02_V021.npy\n",
      "D:\\CS\\2023 HCM AI CHALLENGE\\clip-features-vit-b32\\L02_V022.npy\n",
      "D:\\CS\\2023 HCM AI CHALLENGE\\clip-features-vit-b32\\L02_V023.npy\n",
      "D:\\CS\\2023 HCM AI CHALLENGE\\clip-features-vit-b32\\L02_V024.npy\n",
      "D:\\CS\\2023 HCM AI CHALLENGE\\clip-features-vit-b32\\L02_V025.npy\n",
      "D:\\CS\\2023 HCM AI CHALLENGE\\clip-features-vit-b32\\L02_V026.npy\n",
      "D:\\CS\\2023 HCM AI CHALLENGE\\clip-features-vit-b32\\L02_V027.npy\n",
      "D:\\CS\\2023 HCM AI CHALLENGE\\clip-features-vit-b32\\L02_V028.npy\n",
      "D:\\CS\\2023 HCM AI CHALLENGE\\clip-features-vit-b32\\L02_V029.npy\n",
      "D:\\CS\\2023 HCM AI CHALLENGE\\clip-features-vit-b32\\L02_V030.npy\n"
     ]
    }
   ],
   "source": [
    "embedding_dict = {}\n",
    "for v in all_video:\n",
    "    clip_path = f'D:\\\\CS\\\\2023 HCM AI CHALLENGE\\\\clip-features-vit-b32\\\\{v}.npy'\n",
    "    a = np.load(clip_path)\n",
    "    embedding_dict[v] = {}\n",
    "    for i,k in enumerate(video_keyframe_dict[v]):\n",
    "        embedding_dict[v][k] = a[i]\n",
    "    print(clip_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ea0432e",
   "metadata": {},
   "source": [
    "Tạo danh sách `clip_embedding` ứng với danh sách `sample` trong `dataset`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1ad16b5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "clip_embeddings = []\n",
    "for sample in dataset:\n",
    "    clip_embedding = embedding_dict[sample['video']][sample['frameid']]\n",
    "    clip_embeddings.append(clip_embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12d1ff7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "run_keys = fob.similarity.Similarity.list_runs(dataset)\n",
    "run_keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "655d2feb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# image_index = fob.compute_similarity(\n",
    "#     dataset,\n",
    "#     model=\"clip-vit-base32-torch\",      # store model's name for future use\n",
    "#     embeddings=clip_embeddings,          # precomputed image embeddings    \n",
    "#     brain_key=\"img_sim_32\",\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "95e58ebd",
   "metadata": {},
   "outputs": [],
   "source": [
    "fob.similarity.Similarity.delete_run(dataset, \"img_sim_32_qdrant\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99223338",
   "metadata": {},
   "source": [
    "## Từ đây các bạn có thể thử các tính năng search, filter trên ứng dụng fiftyone."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46605386",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Bạn cần phải cài version umap-learn hỗ trợ.\n",
    "# fob.compute_visualization(\n",
    "#     dataset, \n",
    "#     embeddings=clip_embeddings, \n",
    "#     brain_key=\"img_viz\"\n",
    "# )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "1cdf64a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Perform a text query\n",
    "# query = \"Sunset over city skyline, golden hues.\"\n",
    "# view = dataset.sort_by_similarity(query, k=15, brain_key=\"img_sim_32\")\n",
    "\n",
    "# session.view = view"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a972529d",
   "metadata": {},
   "source": [
    "#### **Try qdrant integration**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9873bb27",
   "metadata": {},
   "outputs": [],
   "source": [
    "qdrant_index = fob.compute_similarity(\n",
    "    dataset, \n",
    "    model = \"clip-vit-base32-torch\",     \n",
    "    embeddings=clip_embeddings,          # precomputed image embeddings  \n",
    "    brain_key = \"img_sim_32_qdrant\", \n",
    "    backend=\"qdrant\",\n",
    "    metric=\"cosine\",\n",
    "    collection_name = \"aic2023-kf-1-clip\"\n",
    ")\n",
    "dataset.save()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37331860",
   "metadata": {},
   "source": [
    "#### **Embed text prompts**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f3884c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from pkg_resources import packaging\n",
    "import torch\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "if packaging.version.parse(\n",
    "  torch.__version__\n",
    ") < packaging.version.parse(\"1.8.0\"):\n",
    "  dtype = torch.long\n",
    "else:\n",
    "  dtype = torch.int\n",
    "\n",
    "\n",
    "\n",
    "def get_text_embedding(prompt, clip_model):\n",
    "    tokenizer = clip_model._tokenizer\n",
    "\n",
    "    # standard start-of-text token\n",
    "    sot_token = tokenizer.encoder[\"<|startoftext|>\"]\n",
    "\n",
    "    # standard end-of-text token\n",
    "    eot_token = tokenizer.encoder[\"<|endoftext|>\"]\n",
    "\n",
    "    prompt_tokens = tokenizer.encode(prompt)\n",
    "    all_tokens = [[sot_token] + prompt_tokens + [eot_token]]\n",
    "\n",
    "    text_features = torch.zeros(\n",
    "        len(all_tokens),\n",
    "        clip_model.config.context_length,\n",
    "        dtype=dtype,\n",
    "        device=device,\n",
    "    )\n",
    "\n",
    "    # insert tokens into feature vector\n",
    "    text_features[0, : len(all_tokens[0])] = torch.tensor(all_tokens)\n",
    "\n",
    "    # encode text\n",
    "    embedding = clip_model._model.encode_text(text_features).to(device)\n",
    "\n",
    "    # convert to list for Pinecone\n",
    "    return embedding.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c1b65a6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "L01_V009_0139\n",
      "L01_V005_0130\n",
      "L01_V009_0104\n",
      "L01_V009_0103\n",
      "L02_V005_0219\n",
      "L02_V005_0218\n",
      "L01_V022_0099\n",
      "L02_V025_0106\n",
      "L02_V005_0171\n",
      "L01_V016_0120\n",
      "L01_V025_0154\n",
      "L01_V012_0109\n",
      "L02_V025_0107\n",
      "L02_V005_0187\n",
      "L01_V012_0092\n",
      "L02_V015_0226\n",
      "L02_V001_0263\n",
      "L02_V022_0192\n",
      "L02_V018_0064\n",
      "L02_V017_0062\n",
      "L01_V022_0098\n",
      "L02_V018_0325\n",
      "L02_V011_0034\n",
      "L02_V010_0229\n",
      "L02_V024_0315\n"
     ]
    }
   ],
   "source": [
    "# 2 stages\n",
    "\n",
    "from fiftyone import ViewField as F\n",
    "\n",
    "# model = foz.load_zoo_model(\"clip-vit-base32-torch\")\n",
    "# prompt = \"Sunset over city skyline, golden hues.\"\n",
    "# query_vector = get_text_embedding(prompt, model)\n",
    "# stage = dataset.sort_by_similarity(query_vector[0], k=16, brain_key=\"img_sim_32_qdrant\")\n",
    "\n",
    "query1 = \"a laptop with some mobile phones on a table\"\n",
    "query2 = \"laptop AND mobile phones\"\n",
    "view1 = (dataset\n",
    "        .sort_by_similarity(query1, k=25, brain_key=\"img_sim_32_qdrant\")     \n",
    "        .sort_by_similarity(query2, k=25, brain_key=\"img_sim_32_qdrant\")               \n",
    "        # .filter_labels(\"object_faster_rcnn\", F(\"label\").is_in([\"Mobile phone\"]))\n",
    ")\n",
    "\n",
    "for sample in view1:\n",
    "    print(f\"{sample.video}_{sample.frameid}\")\n",
    "\n",
    "session.view = view1.view()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "b7877f06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "L01_V027_0089\n",
      "L02_V017_0205\n",
      "L02_V001_0262\n",
      "L01_V013_0110\n",
      "L02_V011_0010\n",
      "L02_V020_0223\n",
      "L02_V020_0010\n",
      "L02_V009_0235\n",
      "L01_V019_0085\n",
      "L02_V020_0224\n",
      "L02_V008_0202\n",
      "L01_V019_0086\n",
      "L02_V005_0242\n",
      "L02_V020_0232\n",
      "L01_V019_0093\n",
      "L01_V030_0159\n",
      "L02_V019_0186\n",
      "L01_V013_0036\n",
      "L01_V019_0094\n",
      "L02_V023_0249\n",
      "L02_V012_0018\n",
      "L02_V001_0041\n",
      "L02_V001_0257\n",
      "L02_V013_0256\n",
      "L02_V001_0210\n"
     ]
    }
   ],
   "source": [
    "query2 = \"only one man in green clothes\"\n",
    "view2 = (dataset\n",
    "        .sort_by_similarity(query2, k=25, brain_key=\"img_sim_32_qdrant\")       \n",
    ")\n",
    "\n",
    "for sample in view2:\n",
    "    print(f\"{sample.video}_{sample.frameid}\")\n",
    "\n",
    "session.view = view2.view()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "fb6755d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1 stage\n",
    "\n",
    "query = \"Sunset over city skyline, golden hues.\"\n",
    "view = dataset.sort_by_similarity(query, k=25, brain_key=\"img_sim_32_qdrant\")\n",
    "\n",
    "session.view = view.view()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09843082",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fob.compute_similarity(\n",
    "#     dataset, \n",
    "#     model=\"clip-vit-base32-torch\",\n",
    "#     patches_field=\"object_faster_rcnn\",\n",
    "#     brain_key = \"qdrant_clip_patches\", \n",
    "#     backend=\"qdrant\",\n",
    "#     metric=\"cosine\",\n",
    "#     collection_name=\"fiftyone-patches\"\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f14d931",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'SklearnSimilarityIndex' object has no attribute 'query'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[37], line 5\u001b[0m\n\u001b[0;32m      2\u001b[0m prompt \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39ma person holding a baseball bat\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m      3\u001b[0m query_vector \u001b[39m=\u001b[39m get_text_embedding(prompt, model)\n\u001b[1;32m----> 5\u001b[0m top_k_samples \u001b[39m=\u001b[39m image_index\u001b[39m.\u001b[39;49mquery(\n\u001b[0;32m      6\u001b[0m     vector\u001b[39m=\u001b[39mquery_vector,\n\u001b[0;32m      7\u001b[0m     top_k\u001b[39m=\u001b[39m\u001b[39m10\u001b[39m,\n\u001b[0;32m      8\u001b[0m     include_values\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m\n\u001b[0;32m      9\u001b[0m )[\u001b[39m'\u001b[39m\u001b[39mmatches\u001b[39m\u001b[39m'\u001b[39m]\n\u001b[0;32m     11\u001b[0m \u001b[39m# get ids of samples that most resemble a person holding a baseball bat\u001b[39;00m\n\u001b[0;32m     12\u001b[0m top_k_ids \u001b[39m=\u001b[39m [res[\u001b[39m'\u001b[39m\u001b[39mid\u001b[39m\u001b[39m'\u001b[39m] \u001b[39mfor\u001b[39;00m res \u001b[39min\u001b[39;00m top_k_samples]\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'SklearnSimilarityIndex' object has no attribute 'query'"
     ]
    }
   ],
   "source": [
    "# model = foz.load_zoo_model(\"clip-vit-base32-torch\")\n",
    "# prompt = \"a person holding a baseball bat\"\n",
    "# query_vector = get_text_embedding(prompt, model)\n",
    "\n",
    "# top_k_samples = image_index.query(\n",
    "#     vector=query_vector,\n",
    "#     top_k=10,\n",
    "#     include_values=False\n",
    "# )['matches']\n",
    "\n",
    "# # get ids of samples that most resemble a person holding a baseball bat\n",
    "# top_k_ids = [res['id'] for res in top_k_samples]\n",
    "\n",
    "# # view these samples, ordered by similarity\n",
    "# view = dataset.select(top_k_ids, ordered=True)\n",
    "# session.view = view.view()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08d251e4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
